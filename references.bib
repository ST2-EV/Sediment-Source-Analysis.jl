@book{abramowitz_HandbookMathematicalFunctions_1972,
  title = {Handbook of Mathematical Functions: With Formulas, Graphs and Mathematical Tables},
  shorttitle = {Handbook of Mathematical Functions},
  author = {Abramowitz, Milton and Stegun, Irene A.},
  editora = {Conference on mathematical tables and National science foundation and Massachusetts institute of technology},
  editoratype = {collaborator},
  date = {1972},
  series = {Dover Books on Advanced Mathematics},
  edition = {Unabridged, unaltered and corr. republ. of the 1964 ed},
  publisher = {{Dover publ}},
  location = {{New York}},
  isbn = {978-0-486-61272-0},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\L7T95WSD\\abramowitz_and_stegun.pdf}
}

@unpublished{austin_TensorRankPrediction_2014,
  title = {Tensor {{Rank Prediction}} via {{Cross Validation}}},
  author = {Austin, Woody and Kolda, Tamara G. and Plantenga, Todd},
  date = {2014-08-13},
  langid = {english},
  venue = {{Sandia National Labs, Livermore, CA}},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\XNI9XGNS\\Austin - Tensor Rank Prediction via Cross Validation.pdf}
}

@book{barber_BayesianReasoningMachine_2012a,
  title = {Bayesian {{Reasoning}} and {{Machine Learning}}},
  author = {Barber, David},
  date = {2012-06-05},
  edition = {1},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511804779},
  url = {https://www.cambridge.org/core/product/identifier/9780511804779/type/book},
  urldate = {2023-08-14},
  abstract = {Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.},
  isbn = {978-0-521-51814-7},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\494KFDMV\\Barber - 2012 - Bayesian Reasoning and Machine Learning.pdf}
}

@article{besancon_DistributionsJlDefinition_2021,
  title = {Distributions.Jl: {{Definition}} and {{Modeling}} of {{Probability Distributions}} in the {{JuliaStats Ecosystem}}},
  shorttitle = {Distributions.Jl},
  author = {Besançon, Mathieu and Papamarkou, Theodore and Anthoff, David and Arslan, Alex and Byrne, Simon and Lin, Dahua and Pearson, John},
  date = {2021},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {98},
  number = {16},
  eprint = {1907.08611},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  issn = {1548-7660},
  doi = {10.18637/jss.v098.i16},
  url = {http://arxiv.org/abs/1907.08611},
  urldate = {2023-06-29},
  abstract = {Random variables and their distributions are a central part in many areas of statistical methods. The Distributions.jl package provides Julia users and developers tools for working with probability distributions, leveraging Julia features for their intuitive and flexible manipulation, while remaining highly efficient through zero-cost abstractions.},
  keywords = {Computer Science - Mathematical Software,Statistics - Computation},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\KEQKW4A9\\Besançon et al. - 2021 - Distributions.jl Definition and Modeling of Proba.pdf;C\:\\Users\\Nicholas\\Zotero\\storage\\L678EHPK\\1907.html}
}

@article{fu_ModelSelectionNonNegative_2019,
  title = {Model {{Selection}} for {{Non-Negative Tensor Factorization}} with {{Minimum Description Length}}},
  author = {Fu, Yunhui and Matsushima, Shin and Yamanishi, Kenji},
  date = {2019-06-27},
  journaltitle = {Entropy},
  shortjournal = {Entropy (Basel)},
  volume = {21},
  number = {7},
  eprint = {33267345},
  eprinttype = {pmid},
  pages = {632},
  issn = {1099-4300},
  doi = {10.3390/e21070632},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7515125/},
  urldate = {2023-08-16},
  abstract = {Non-negative tensor factorization (NTF) is a widely used multi-way analysis approach that factorizes a high-order non-negative data tensor into several non-negative factor matrices. In NTF, the non-negative rank has to be predetermined to specify the model and it greatly influences the factorized matrices. However, its value is conventionally determined by specialists’ insights or trial and error. This paper proposes a novel rank selection criterion for NTF on the basis of the minimum description length (MDL) principle. Our methodology is unique in that (1) we apply the MDL principle on tensor slices to overcome a problem caused by the imbalance between the number of elements in a data tensor and that in factor matrices, and (2) we employ the normalized maximum likelihood (NML) code-length for histogram densities. We employ synthetic and real data to empirically demonstrate that our method outperforms other criteria in terms of accuracies for estimating true ranks and for completing missing values. We further show that our method can produce ranks suitable for knowledge discovery.},
  pmcid = {PMC7515125},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\MWKWLEUA\\Fu et al. - 2019 - Model Selection for Non-Negative Tensor Factorizat.pdf}
}

@article{hitchcockExpressionTensorPolyadic1927,
  title = {The {{Expression}} of a {{Tensor}} or a {{Polyadic}} as a {{Sum}} of {{Products}}},
  author = {Hitchcock, Frank L.},
  date = {1927},
  journaltitle = {Journal of Mathematics and Physics},
  volume = {6},
  number = {1-4},
  pages = {164--189},
  issn = {1467-9590},
  doi = {10.1002/sapm192761164},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sapm192761164},
  urldate = {2023-08-24},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\3HXJIHYZ\\Hitchcock - 1927 - The Expression of a Tensor or a Polyadic as a Sum .pdf;C\:\\Users\\Nicholas\\Zotero\\storage\\MVJ6BWTI\\sapm192761164.html}
}

@article{kolda_TensorDecompositionsApplications_2009,
  title = {Tensor {{Decompositions}} and {{Applications}}},
  author = {Kolda, Tamara G. and Bader, Brett W.},
  date = {2009-08-06},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  volume = {51},
  number = {3},
  pages = {455--500},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/07070111X},
  url = {http://epubs.siam.org/doi/10.1137/07070111X},
  urldate = {2022-11-01},
  abstract = {This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A tensor is a multidimensional or N -way array. Decompositions of higher-order tensors (i.e., N -way arrays with N ≥ 3) have applications in psychometrics, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, and elsewhere. Two particular tensor decompositions can be considered to be higher-order extensions of the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes a tensor as a sum of rank-one tensors, and the Tucker decomposition is a higher-order form of principal component analysis. There are many other tensor decompositions, including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, and PARATUCK2 as well as nonnegative variants of all of the above. The N-way Toolbox, Tensor Toolbox, and Multilinear Engine are examples of software packages for working with tensors.},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\5HV3NICR\\Kolda and Bader - 2009 - Tensor Decompositions and Applications.pdf}
}

@inproceedings{lee_AlgorithmsNonnegativeMatrix_2000,
  title = {Algorithms for {{Non-negative Matrix Factorization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lee, Daniel and Seung, H. Sebastian},
  date = {2000},
  volume = {13},
  publisher = {{MIT Press}},
  url = {https://papers.nips.cc/paper/2000/hash/f9d1152547c0bde01830b7e8bd60024c-Abstract.html},
  urldate = {2023-03-20},
  abstract = {Non-negative matrix factorization (NMF) has previously been shown to  be a useful decomposition for multivariate data. Two different multi-  plicative algorithms for NMF are analyzed. They differ only slightly in  the multiplicative factor used in the update rules. One algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized Kullback-Leibler divergence. The monotonic  convergence of both algorithms can be proven using an auxiliary func-  tion analogous to that used for proving convergence of the Expectation-  Maximization algorithm. The algorithms can also be interpreted as diag-  onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence.},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\XLEK752V\\Lee and Seung - 2000 - Algorithms for Non-negative Matrix Factorization.pdf}
}

@article{lee_RecognizingPorphyryCopper_2021,
  title = {Recognizing {{Porphyry Copper Potential From Till Zircon Composition}}: {{A Case Study From The Highland Valley Porphyry District}}, {{South-central British Columbia}}},
  shorttitle = {{{RECOGNIZING PORPHYRY COPPER POTENTIAL FROM TILL ZIRCON COMPOSITION}}},
  author = {Lee, Robert G. and Plouffe, Alain and Ferbey, Travis and Hart, Craig J.R. and Hollings, Pete and Gleeson, Sarah A.},
  date = {2021-06-01},
  journaltitle = {Economic Geology},
  shortjournal = {Economic Geology},
  volume = {116},
  number = {4},
  pages = {1035--1045},
  issn = {0361-0128},
  doi = {10.5382/econgeo.4808},
  url = {https://doi.org/10.5382/econgeo.4808},
  urldate = {2023-08-17},
  abstract = {The detrital zircons in tills overlying the Guichon Creek batholith, British Columbia, Canada, have trace element concentrations and ages similar to those of zircons from the bedrock samples from which they are interpreted to have been sourced. Rocks from the core of the batholith that host porphyry copper mineralization have distinct zircon compositions relative to the distal, barren margin. We analyzed 296 zircons separated from 12 subglacial till samples to obtain U-Pb ages and trace element compositions. Laser ablation U-Pb ages of the detrital zircons overlap within error with chemical abrasion-thermal ionization mass spectrometry U-Pb ages of the Late Triassic Guichon Creek batholith and confirm that the detrital zircons are likely derived from the batholith. The youngest intrusions of the batholith produced the Highland Valley Copper porphyry deposits and contain distinctive zircons with elevated Eu/EuN* \&gt;0.4 attributed to high magmatic water contents and oxidation states, indicating higher porphyry copper potential. Zircon from till samples adjacent to and 9~km down-ice from the mineralized centers have mean Eu/EuN* \&gt;0.4, which are indicative of potential porphyry copper mineralization. Detrital zircon grains from more distal up- and down-ice locations (10–15~km) have zircon Eu/EuN* mean values of 0.26 to 0.37, reflecting background values. We conclude that detrital zircon compositions in glacial sediments transported several kilometers can be used to establish the regional potential for porphyry copper mineralization.},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\A2NN8TPJ\\Lee et al. - 2021 - RECOGNIZING PORPHYRY COPPER POTENTIAL FROM TILL ZI.pdf;C\:\\Users\\Nicholas\\Zotero\\storage\\E7RLQK99\\RECOGNIZING-PORPHYRY-COPPER-POTENTIAL-FROM-TILL.html}
}

@article{leone_FoldedNormalDistribution_1961,
  title = {The {{Folded Normal Distribution}}},
  author = {Leone, F. C. and Nelson, L. S. and Nottingham, R. B.},
  date = {1961},
  journaltitle = {Technometrics},
  volume = {3},
  number = {4},
  eprint = {1266560},
  eprinttype = {jstor},
  pages = {543--550},
  publisher = {{[Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]}},
  issn = {0040-1706},
  doi = {10.2307/1266560},
  url = {https://www.jstor.org/stable/1266560},
  urldate = {2023-08-09},
  abstract = {Measurements are frequently recorded without their algebraic sign. As a consequence, the underlying distribution of measurements is replaced by a distribution of absolute measurements. When the underlying distribution is normal, the resulting distribution is called the "folded normal distribution". The authors describe methods for estimating the mean and standard deviation of the normal distribution based on estimates of the mean and standard deviation determined from the folded normal. Tables are provided to assist in the estimation procedure and an example included.}
}

@article{luo_TensorFactorizationPrecision_2017,
  title = {Tensor Factorization toward Precision Medicine},
  author = {Luo, Yuan and Wang, Fei and Szolovits, Peter},
  date = {2017-05-01},
  journaltitle = {Briefings in Bioinformatics},
  shortjournal = {Briefings in Bioinformatics},
  volume = {18},
  number = {3},
  pages = {511--514},
  issn = {1467-5463},
  doi = {10.1093/bib/bbw026},
  url = {https://doi.org/10.1093/bib/bbw026},
  urldate = {2023-08-21},
  abstract = {Precision medicine initiatives come amid the rapid growth in quantity and variety of biomedical data, which exceeds the capacity of matrix-oriented data representations and many current analysis algorithms. Tensor factorizations extend the matrix view to multiple modalities and support dimensionality reduction methods that identify latent groups of data for meaningful summarization of both features and instances. In this opinion article, we analyze the modest literature on applying tensor factorization to various biomedical fields including genotyping and phenotyping. Based on the cited work including work of our own, we suggest that tensor applications could serve as an effective tool to enable frequent updating of medical knowledge based on the continually growing scientific and clinical evidence. We encourage extensive experimental studies to tackle challenges including design choice of factorizations, integrating temporality and algorithm scalability.},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\QU64YAAC\\Luo et al. - 2017 - Tensor factorization toward precision medicine.pdf;C\:\\Users\\Nicholas\\Zotero\\storage\\VP5B8L3D\\2453284.html}
}

@incollection{nesterov_NonlinearOptimization_2018,
  title = {Nonlinear {{Optimization}}},
  booktitle = {Lectures on {{Convex Optimization}}},
  author = {Nesterov, Yurii},
  editor = {Nesterov, Yurii},
  date = {2018},
  series = {Springer {{Optimization}} and {{Its Applications}}},
  pages = {3--58},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-91578-4_1},
  url = {https://doi.org/10.1007/978-3-319-91578-4_1},
  urldate = {2023-08-16},
  abstract = {In this chapter, we introduce the main notations and concepts used in Continuous Optimization. The first theoretical results are related to Complexity Analysis of the problems of Global Optimization. For these problems, we start with a very pessimistic lower performance guarantee. It implies that for any method there exists an optimization problem in ℝn\$\$\textbackslash mathbb \{R\}\^n\$\$which needs at least O1𝜖n\$\$O\textbackslash left (\{1 \textbackslash over \textbackslash epsilon \^n\}\textbackslash right )\$\$computations of the function values in order to approximate its global solution up to accuracy 𝜖. Therefore, in the next section we pass to local optimization, and consider two main methods, the Gradient Method and the Newton Method. For both of them, we establish some local rates of convergence. In the last section, we present some standard methods in General Nonlinear Optimization: the conjugate gradient methods, quasi-Newton methods, theory of Lagrangian relaxation, barrier methods and penalty function methods. For some of them, we prove global convergence results.},
  isbn = {978-3-319-91578-4},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\IGK2TSNL\\Nesterov - 2018 - Nonlinear Optimization.pdf}
}

@article{papastergiou_TensorDecompositionMultipleInstance_2018,
  title = {Tensor {{Decomposition}} for {{Multiple-Instance Classification}} of {{High-Order Medical Data}}},
  author = {Papastergiou, Thomas and Zacharaki, Evangelia I. and Megalooikonomou, Vasileios},
  date = {2018-12-06},
  journaltitle = {Complexity},
  shortjournal = {Complexity},
  volume = {2018},
  pages = {1--13},
  issn = {1076-2787, 1099-0526},
  doi = {10.1155/2018/8651930},
  url = {https://www.hindawi.com/journals/complexity/2018/8651930/},
  urldate = {2023-08-21},
  abstract = {Multidimensional data that occur in a variety of applications in clinical diagnostics and health care can naturally be represented by multidimensional arrays (i.e., tensors). Tensor decompositions offer valuable and powerful tools for latent concept discovery that can handle effectively missing values and noise. We propose a seamless, application-independent feature extraction and multiple-instance (MI) classification method, which represents the raw multidimensional, possibly incomplete, data by means of learning a high-order dictionary. The effectiveness of the proposed method is demonstrated in two application scenarios: (i) prediction of frailty in older people using multisensor recordings and (ii) breast cancer classification based on histopathology images. The proposed method outperforms or is comparable to the state-of-the-art multiple-instance learning classifiers highlighting its potential for computer-assisted diagnosis and health care support.},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\PK64LU7F\\Papastergiou et al. - 2018 - Tensor Decomposition for Multiple-Instance Classif.pdf}
}

@online{qi_TripleDecompositionTensor_2020,
  title = {Triple {{Decomposition}} and {{Tensor Recovery}} of {{Third Order Tensors}}},
  author = {Qi, Liqun and Chen, Yannan and Bakshi, Mayank and Zhang, Xinzhen},
  date = {2020-03-01},
  eprint = {2002.02259},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  doi = {10.48550/arXiv.2002.02259},
  url = {http://arxiv.org/abs/2002.02259},
  urldate = {2023-08-01},
  abstract = {In this paper, we introduce a new tensor decomposition for third order tensors, which decomposes a third order tensor to three third order low rank tensors in a balanced way. We call such a decomposition the triple decomposition, and the corresponding rank the triple rank. For a third order tensor, its CP decomposition can be regarded as a special case of its triple decomposition. The triple rank of a third order tensor is not greater than the middle value of the Tucker rank, and is strictly less than the middle value of the Tucker rank for an essential class of examples. These indicate that practical data can be approximated by low rank triple decomposition as long as it can be approximated by low rank CP or Tucker decomposition. This theoretical discovery is confirmed numerically. Numerical tests show that third order tensor data from practical applications such as internet traffic and video image are of low triple ranks. A tensor recovery method based on low rank triple decomposition is proposed. Its convergence and convergence rate are established. Numerical experiments confirm the efficiency of this method.},
  pubstate = {preprint},
  keywords = {Mathematics - Numerical Analysis},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\XNXUKF5Z\\Qi et al. - 2020 - Triple Decomposition and Tensor Recovery of Third .pdf;C\:\\Users\\Nicholas\\Zotero\\storage\\G8MNVYR8\\2002.html}
}

@book{rockafellar_ConvexAnalysis_1970,
  title = {Convex Analysis},
  author = {Rockafellar, R. Tyrrell},
  date = {1970},
  series = {Princeton Mathematical Series},
  number = {28},
  publisher = {{Princeton University Press}},
  location = {{Princeton, N.J}},
  isbn = {978-0-691-08069-7},
  langid = {english},
  pagetotal = {451},
  keywords = {Convex domains,Mathematical analysis},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\HRFQKU44\\Rockafellar - 1970 - Convex analysis.pdf}
}

@article{saylor_CharacterizingSedimentSources_2019,
  title = {Characterizing Sediment Sources by Non-Negative Matrix Factorization of Detrital Geochronological Data},
  author = {Saylor, J.E. and Sundell, K.E. and Sharman, G.R.},
  date = {2019-04},
  journaltitle = {Earth and Planetary Science Letters},
  shortjournal = {Earth and Planetary Science Letters},
  volume = {512},
  pages = {46--58},
  issn = {0012821X},
  doi = {10.1016/j.epsl.2019.01.044},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0012821X19300706},
  urldate = {2023-05-05},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\SQJ3V4JZ\\Saylor et al. - 2019 - Characterizing sediment sources by non-negative ma.pdf}
}

@book{silverman_DensityEstimationStatistics_1986,
  title = {Density {{Estimation}} for {{Statistics}} and {{Data Analysis}}},
  author = {Silverman, Bernard W.},
  date = {1986-04-01},
  publisher = {{CRC Press}},
  abstract = {Although there has been a surge of interest in density estimation in recent years, much of the published research has been concerned with purely technical matters with insufficient emphasis given to the technique's practical value. Furthermore, the subject has been rather inaccessible to the general statistician.The account presented in this book places emphasis on topics of methodological importance, in the hope that this will facilitate broader practical application of density estimation and also encourage research into relevant theoretical work. The book also provides an introduction to the subject for those with general interests in statistics. The important role of density estimation as a graphical technique is reflected by the inclusion of more than 50 graphs and figures throughout the text.Several contexts in which density estimation can be used are discussed, including the exploration and presentation of data, nonparametric discriminant analysis, cluster analysis, simulation and the bootstrap, bump hunting, projection pursuit, and the estimation of hazard rates and other quantities that depend on the density. This book includes general survey of methods available for density estimation. The Kernel method, both for univariate and multivariate data, is discussed in detail, with particular emphasis on ways of deciding how much to smooth and on computation aspects. Attention is also given to adaptive methods, which smooth to a greater degree in the tails of the distribution, and to methods based on the idea of penalized likelihood.},
  isbn = {978-0-412-24620-3},
  langid = {english},
  pagetotal = {190},
  keywords = {Mathematics / Probability \& Statistics / General}
}

@article{sundell_CrustalThickeningNorthern_2022,
  title = {Crustal {{Thickening}} of the {{Northern Central Andean Plateau Inferred From Trace Elements}} in {{Zircon}}},
  author = {Sundell, Kurt E. and George, Sarah W.M. and Carrapa, Barbara and Gehrels, George E. and Ducea, Mihai N. and Saylor, Joel E. and Pepper, Martin},
  date = {2022},
  journaltitle = {Geophysical Research Letters},
  volume = {49},
  number = {3},
  pages = {e2021GL096443},
  issn = {1944-8007},
  doi = {10.1029/2021GL096443},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021GL096443},
  urldate = {2023-06-30},
  abstract = {The timing of crustal thickening in the northern Central Andean Plateau (CAP), at 13–20°S, and its relationship to surface uplift is debated. Zircon qualitatively records crustal thickness as its trace element chemistry is controlled by the growth of cogenetic minerals and relative uptake of light and heavy Rare Earth Elements. Jurassic to Neogene zircons from volcanic rocks, sandstones, and river sediments reveal shifts in trace element ratios suggesting major crustal thickening at 80–55 Ma and 35–0 Ma, coincident with high-flux magmatism. An intervening magmatic lull due to shallow subduction obscures the magmatic record from 55 to 35 Ma during which thickening continued via crustal shortening. Protracted thickening since the Late Cretaceous correlates with early elevation gain of the CAP western margin, but contrasts with Miocene establishment of near modern elevation in the northern CAP and the onset of hyperaridity along the Pacific coast, highlighting their complex spatial and temporal relationship.},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\BCGQI646\\Sundell et al. - 2022 - Crustal Thickening of the Northern Central Andean .pdf;C\:\\Users\\Nicholas\\Zotero\\storage\\NPXWRL5H\\2021GL096443.html}
}

@book{vershynin_HighDimensionalProbability_2018,
  title = {High-{{Dimensional Probability}}},
  author = {Vershynin, Roman},
  date = {2018-10},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  publisher = {{Cambridge University Press}},
  location = {{University of California, Irvine}},
  url = {https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.html#},
  urldate = {2023-04-11},
  isbn = {978-1-108-24625-5},
  langid = {english},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\BFQVITX9\\Vershynin - High-Dimensional Probability.pdf;C\:\\Users\\Nicholas\\Zotero\\storage\\I27NIDQR\\high-dimensional-probability-introduction-applications-data-science.html}
}

@incollection{wenBlockCoordinateDescent2012,
  title = {Block {{Coordinate Descent Methods}} for {{Semidefinite Programming}}},
  booktitle = {Handbook on {{Semidefinite}}, {{Conic}} and {{Polynomial Optimization}}},
  author = {Wen, Zaiwen and Goldfarb, Donald and Scheinberg, Katya},
  editor = {Anjos, Miguel F. and Lasserre, Jean B.},
  date = {2012},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  pages = {533--564},
  publisher = {{Springer US}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4614-0769-0_19},
  url = {https://doi.org/10.1007/978-1-4614-0769-0_19},
  urldate = {2023-08-28},
  abstract = {We consider in this chapter block coordinate descent (BCD) methods for solving semidefinite programming (SDP) problems. These methods are based on sequentially minimizing the SDP problem’s objective function over blocks of variables corresponding to the elements of a single row (and column) of the positive semidefinite matrix X; hence, we will also refer to these methods as row-by-row (RBR) methods. Using properties of the (generalized) Schur complement with respect to the remaining fixed (n − 1)-dimensional principal submatrix of X, the positive semidefiniteness constraint on X reduces to a simple second-order cone constraint. It is well known that without certain safeguards, BCD methods cannot be guaranteed to converge in the presence of general constraints. Hence, to handle linear equality constraints, the methods that we describe here use an augmented Lagrangian approach. Since BCD methods are first-order methods, they are likely to work well only if each subproblem minimization can be performed very efficiently. Fortunately, this is the case for several important SDP problems, including the maxcut SDP relaxation and the minimum nuclear norm matrix completion problem, since closed-form solutions for the BCD subproblems that arise in these cases are available. We also describe how BCD can be applied to solve the sparse inverse covariance estimation problem by considering a dual formulation of this problem. The BCD approach is further generalized by using a rank-two update so that the coordinates can be changed in more than one row and column at each iteration. Finally, numerical results on the maxcut SDP relaxation and matrix completion problems are presented to demonstrate the robustness and efficiency of the BCD approach, especially if only moderately accurate solutions are desired.},
  isbn = {978-1-4614-0769-0},
  langid = {english},
  keywords = {Augmented Lagrangian Function,Augmented Lagrangian Method,Cholesky Factorization,Coordinate Descent Method,Matrix Completion},
  file = {C\:\\Users\\Nicholas\\Zotero\\storage\\XL4KE66R\\Wen et al. - 2012 - Block Coordinate Descent Methods for Semidefinite .pdf}
}

@article{xu_BlockCoordinateDescent_2013,
  title = {A {{Block Coordinate Descent Method}} for {{Regularized Multiconvex Optimization}} with {{Applications}} to {{Nonnegative Tensor Factorization}} and {{Completion}}},
  author = {Xu, Yangyang and Yin, Wotao},
  date = {2013-01},
  journaltitle = {SIAM Journal on Imaging Sciences},
  shortjournal = {SIAM J. Imaging Sci.},
  volume = {6},
  number = {3},
  pages = {1758--1789},
  issn = {1936-4954},
  doi = {10.1137/120887795},
  url = {http://epubs.siam.org/doi/10.1137/120887795},
  urldate = {2023-05-08},
  langid = {english}
}
